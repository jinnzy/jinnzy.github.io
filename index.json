[{"categories":["default"],"content":"由于线上很多k8s集群的证书要过期了，虽然升级集群会更新证书，但是线上很多专属云k8s集群不方便升级，所以选择了手动更新证书，这里记录下更新步骤。 本次操作已在1.18.x/1.17.x版本中验证，如果是高版本需要去掉alpha命令。 kubeadm不能管理外部生成的CA证书。 ","date":"2021-04-15","objectID":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/:0:0","tags":["default"],"title":"使用kubeadm手动更新证书","uri":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/"},{"categories":["default"],"content":"1. 查看证书过期时间 # kubeadm alpha certs check-expiration [check-expiration] Reading configuration from the cluster... [check-expiration] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' CERTIFICATE EXPIRES RESIDUAL TIME CERTIFICATE AUTHORITY EXTERNALLY MANAGED admin.conf Apr 29, 2021 06:17 UTC 14d no apiserver Apr 29, 2021 06:17 UTC 14d ca no apiserver-kubelet-client Apr 29, 2021 06:17 UTC 14d ca no controller-manager.conf Apr 29, 2021 06:17 UTC 14d no front-proxy-client Apr 29, 2021 06:17 UTC 14d front-proxy-ca no scheduler.conf Apr 29, 2021 06:17 UTC 14d no CERTIFICATE AUTHORITY EXPIRES RESIDUAL TIME EXTERNALLY MANAGED ca Feb 20, 2030 05:59 UTC 8y no front-proxy-ca Feb 20, 2030 05:59 UTC 8y no 注意：搭建集群时我是使用的外部etcd,所以并没有显示etcd相关的证书。 ","date":"2021-04-15","objectID":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/:0:1","tags":["default"],"title":"使用kubeadm手动更新证书","uri":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/"},{"categories":["default"],"content":"2. 备份 证书 cp -rp /etc/kubernetes /etc/kubernetes.bak etcd,如果是使用kubeadm创建的etcd最好备份一下etcd,我这里使用的外部etcd并且有定时备份，所以就不备份了 ","date":"2021-04-15","objectID":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/:0:2","tags":["default"],"title":"使用kubeadm手动更新证书","uri":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/"},{"categories":["default"],"content":"3. 更新证书，三台master都执行 # kubeadm alpha certs renew all [renew] Reading configuration from the cluster... [renew] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' certificate embedded in the kubeconfig file for the admin to use and for kubeadm itself renewed certificate for serving the Kubernetes API renewed certificate for the API server to connect to kubelet renewed certificate embedded in the kubeconfig file for the controller manager to use renewed certificate for the front proxy client renewed certificate embedded in the kubeconfig file for the scheduler manager to use renewed 也可以使用—config=/root/kubeadm-config.yml手动指定配置文件，我这里没有加，默认使用kube-system kubeadm-config配置 ","date":"2021-04-15","objectID":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/:0:3","tags":["default"],"title":"使用kubeadm手动更新证书","uri":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/"},{"categories":["default"],"content":"4. 重启kube-apiserver,kube-controller,kube-scheduler，使用新证书，如果etcd使用kubeadm启动的，也需要重启 docker ps |egrep \"k8s_kube-apiserver|k8s_kube-scheduler|k8s_kube-controller\"|awk '{print $1}'|xargs docker restart ","date":"2021-04-15","objectID":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/:0:4","tags":["default"],"title":"使用kubeadm手动更新证书","uri":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/"},{"categories":["default"],"content":"5. 检查证书 # kubeadm alpha certs check-expiration [check-expiration] Reading configuration from the cluster... [check-expiration] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' CERTIFICATE EXPIRES RESIDUAL TIME CERTIFICATE AUTHORITY EXTERNALLY MANAGED admin.conf Apr 15, 2022 03:15 UTC 364d no apiserver Apr 15, 2022 03:15 UTC 364d ca no apiserver-kubelet-client Apr 15, 2022 03:15 UTC 364d ca no controller-manager.conf Apr 15, 2022 03:15 UTC 364d no front-proxy-client Apr 15, 2022 03:15 UTC 364d front-proxy-ca no scheduler.conf Apr 15, 2022 03:15 UTC 364d no CERTIFICATE AUTHORITY EXPIRES RESIDUAL TIME EXTERNALLY MANAGED ca Jan 13, 2031 12:05 UTC 9y no front-proxy-ca Jan 13, 2031 12:05 UTC 9y no /etc/kubernetes/admin.conf 证书 # cat /etc/kubernetes/admin.conf client-certificate-data: LS0tLS1CRUdJTiBDRVJUSU ...... dy9wCkdNNHAzRVBUNFQvN0E5b0sxWk1LRXZCTjRQYnRIV1FpRDN5K3R4TlQwa0RsNTNhUXFHcz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo= base64解析 # echo LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM4akNDQWRxZ0F3SUJBZ0lJS0tCaVB2WFpIN3N3RFFZSktvWklodmNOQV...... Re0E5b0sxWk1LRXZCTjRQYnRIV1FpRDN5K3R4TlQwa0RsNTNhUXFHcz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo= | base64 -d -----BEGIN CERTIFICATE----- MIIC8jCCAdqgAwIBAgIIKKBiPvXZH7swDQYJKoZIhvcNAQELBQAwFTETMBEGA1UE ...... yLRf16OWsanlgH9yed/2pJcvpSRNBoBugOf8wScbR9QxZz9az6INQ95dTBi7zw/p GM4p3EPT4T/7A9oK1ZMKEvBN4PbtHWQiD3y+txNT0kDl53aQqGs= -----END CERTIFICATE----- 拿到ssl证书网站分析一下，也更新了 各个节点的kubelet的证书到期后会自动更新，正好之前集群kubelet节点有一个到期了的，检查日志发现会自动更新，所以就不需要担心了。 certificate rotation detected, shutting down client connections to start using new credentials ","date":"2021-04-15","objectID":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/:0:5","tags":["default"],"title":"使用kubeadm手动更新证书","uri":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/"},{"categories":["default"],"content":"参考资料 https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm-certs/ ","date":"2021-04-15","objectID":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/:0:6","tags":["default"],"title":"使用kubeadm手动更新证书","uri":"/shi-yong-kubeadmshou-dong-geng-xin-zheng-shu/"},{"categories":["ansible"],"content":"概述 前几天使用ansible通过公网方式建立的vpn部署k8s时遇到了几个问题，特别慢，时不时总是断开连接，导致playbook执行不下去，使用mitogen可以解决这些问题。 根据官方文档所述，可以提升1.25-7倍的速度，降低2倍cpu使用。 安装 注意：目前mitogen-0.2.9最新版本仅支持2.9.x的ansible，使用时请注意版本 我是在自己整理的playbook目录下操作的 wget https://networkgenomics.com/try/mitogen-0.2.9.tar.gz 编辑当前目录下的ansible.cfg，添加以下配置，就可体验飞一般的速度了。 [defaults] strategy_plugins = mitogen-0.2.9/ansible_mitogen/plugins/strategy strategy = mitogen_linear ","date":"2021-04-14","objectID":"/shi-yong-mitogenjia-su-ansible/:0:0","tags":["ansible"],"title":"使用mitogen加速ansible","uri":"/shi-yong-mitogenjia-su-ansible/"},{"categories":["kubernetes"],"content":"最近总是接到研发同学反馈线上应用响应慢或无响应及健康检测失败重启之类，查找发现是因为cpu throttling (cpu 节流/受限)。因为线上所有服务都是开启了cpu limit，会导致节流这一现象的发生。 k8s如何实现的资源划分 k8s使用cgroup 进行资源分配，cgroup 是具有层级结构的 /sys/fs/cgroup ├── blkio ├── cpu -\u003e cpu,cpuacct ├── cpuacct -\u003e cpu,cpuacct ├── cpu,cpuacct │ ├── cgroup.clone_children │ ├── cgroup.event_control │ ├── cgroup.procs │ ├── cgroup.sane_behavior │ ├── cpuacct.stat │ ├── cpuacct.usage │ ├── cpuacct.usage_percpu │ ├── cpu.cfs_period_us │ ├── cpu.cfs_quota_us │ ├── cpu.rt_period_us │ ├── cpu.rt_runtime_us │ ├── cpu.shares │ ├── cpu.stat │ ├── kubepods.slice │ ├── kube.slice │ ├── notify_on_release │ ├── release_agent │ ├── system.slice │ ├── tasks │ └── user.slice ├── cpuset │ ├── cgroup.clone_children │ ├── cgroup.event_control │ ├── cgroup.procs │ ├── cgroup.sane_behavior │ ├── cpuset.cpu_exclusive │ ├── cpuset.cpus │ ├── cpuset.effective_cpus │ ├── cpuset.effective_mems │ ├── cpuset.mem_exclusive │ ├── cpuset.mem_hardwall │ ├── cpuset.memory_migrate │ ├── cpuset.memory_pressure │ ├── cpuset.memory_pressure_enabled │ ├── cpuset.memory_spread_page │ ├── cpuset.memory_spread_slab │ ├── cpuset.mems │ ├── cpuset.sched_load_balance │ ├── cpuset.sched_relax_domain_level │ ├── kubepods.slice │ ├── kube.slice │ ├── notify_on_release │ ├── release_agent │ ├── system.slice │ └── tasks ├── devices ├── freezer ├── hugetlb ├── memory │ ├── cgroup.clone_children │ ├── cgroup.event_control │ ├── cgroup.procs │ ├── cgroup.sane_behavior │ ├── kubepods.slice │ ├── kube.slice │ ├── memory.failcnt │ ├── memory.force_empty │ ├── memory.kmem.failcnt │ ├── memory.kmem.limit_in_bytes │ ├── memory.kmem.max_usage_in_bytes │ ├── memory.kmem.slabinfo │ ├── memory.kmem.tcp.failcnt │ ├── memory.kmem.tcp.limit_in_bytes │ ├── memory.kmem.tcp.max_usage_in_bytes │ ├── memory.kmem.tcp.usage_in_bytes │ ├── memory.kmem.usage_in_bytes │ ├── memory.limit_in_bytes │ ├── memory.max_usage_in_bytes │ ├── memory.memsw.failcnt │ ├── memory.memsw.limit_in_bytes │ ├── memory.memsw.max_usage_in_bytes │ ├── memory.memsw.usage_in_bytes │ ├── memory.move_charge_at_immigrate │ ├── memory.numa_stat │ ├── memory.oom_control │ ├── memory.pressure_level │ ├── memory.soft_limit_in_bytes │ ├── memory.stat │ ├── memory.swappiness │ ├── memory.usage_in_bytes │ ├── memory.use_hierarchy │ ├── notify_on_release │ ├── release_agent │ ├── system.slice │ ├── tasks │ └── user.slice ├── net_cls -\u003e net_cls,net_prio ├── net_cls,net_prio ├── net_prio -\u003e net_cls,net_prio ├── perf_event ├── pids │ ├── cgroup.clone_children │ ├── cgroup.event_control │ ├── cgroup.procs │ ├── cgroup.sane_behavior │ ├── kubepods.slice │ ├── kube.slice │ ├── notify_on_release │ ├── pids.current │ ├── release_agent │ ├── system.slice │ ├── tasks │ └── user.slice └── systemd ├── cgroup.clone_children ├── cgroup.event_control ├── cgroup.procs ├── cgroup.sane_behavior ├── kubepods.slice ├── kube.slice ├── notify_on_release ├── release_agent ├── system.slice ├── tasks └── user.slice ","date":"2021-04-08","objectID":"/kuberneteszhong-de-cpu-throttling/:0:0","tags":["kubernetes"],"title":"kubernetes中的cpu throttling","uri":"/kuberneteszhong-de-cpu-throttling/"},{"categories":["kubernetes"],"content":"cpu资源 ","date":"2021-04-08","objectID":"/kuberneteszhong-de-cpu-throttling/:1:0","tags":["kubernetes"],"title":"kubernetes中的cpu throttling","uri":"/kuberneteszhong-de-cpu-throttling/"},{"categories":["kubernetes"],"content":"request cpu request 是通过cpu,cpuacct/kubepods.slice/pod\u003cUID\u003e/xxx/cpu.shares 来实现的 假设这是一个4c的节点，根cgroup为4096 个cpu，子目录cpu.shares的总数却超过了4096,在这种情况下linux cfs会按照cpu.shares值的比例来分配cpu,如：system.slice user.slice获得680个cpu(4096的16.6)，kubepod获得2736个。 如果在空闲情况下前两个cgroup不会使用分配的cpu资源，调度程序避免为使用的cpu浪费，将会把这部分释放到全局资源中，以便分配给需要更多cpu的cgroup 当你指定了某个容器的 CPU request 值为 x millicores 时，kubernetes 会为这个 container 所在的 cgroup 的 cpu.shares 的值指定为 x * 1024 / 1000。即：cpu.shares = (cpu in millicores * 1024) / 1000。 cpu 1核等于1000 millicores 如果资源空闲时，容器可以使用limit上限的cpu,但是当cpu资源不足时会保证容器有request cpu的资源可用 例子：服务的资源设置如下： resources: limits: cpu: \"1\" memory: 1Gi requests: cpu: 500m memory: 512Mi 登陆节点获取pid，查看cpu.shares的值为512，结果为预期的值 docker ps |grep fs-mankeep-task k8s_POD_fs-mankeep-task-656fd776b4-vqznd_fstest_12debdb4-29a5-4fb2-b971-3a8144909a67_0 cat /sys/fs/cgroup/cpu,cpuacct/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod12debdb4_29a5_4fb2_b971_3a8144909a67.slice/cpu.shares 512 ","date":"2021-04-08","objectID":"/kuberneteszhong-de-cpu-throttling/:1:1","tags":["kubernetes"],"title":"kubernetes中的cpu throttling","uri":"/kuberneteszhong-de-cpu-throttling/"},{"categories":["kubernetes"],"content":"limit kubernetes通过 cpu cgroup中的cpu.cfs_period_us cpu.cfs_quota_us两个配置实现的，会保证使用的cpu不会超过cfs_quota_us/cfs_period_us 的值。 与cpu.share不同的是，quota是基于时间段来限制 cpu.cfs_period_us 周期时间 cpu.cfs_quota_us 时间份额，表示在1个period周期允许使用的最大额度 cpu.cfs_period_us = 100000 (i.e. 100ms) cpu.cfs_quota_us = quota = (cpu in millicores * 100000) / 1000 参考文章 https://zhuanlan.zhihu.com/p/38359775 https://medium.com/omio-engineering/cpu-limits-and-aggressive-throttling-in-kubernetes-c5b20bd8a718 ","date":"2021-04-08","objectID":"/kuberneteszhong-de-cpu-throttling/:1:2","tags":["kubernetes"],"title":"kubernetes中的cpu throttling","uri":"/kuberneteszhong-de-cpu-throttling/"},{"categories":["docker"],"content":"使用docker拉取上传 拉取amd64镜像，并重命名tag 上传 docker pull --platform amd64 k8s.gcr.io/kube-apiserver:v1.18.5 docker tag k8s.gcr.io/kube-apiserver:v1.18.5 reg.xxx.cn/kube-apiserver:v1.18.5-amd64 docker push reg.xxx.cn/kube-apiserver:v1.18.5-amd64 拉取arm64镜像 docker pull --platform arm64 k8s.gcr.io/kube-apiserver:v1.18.5 docker tag k8s.gcr.io/kube-apiserver:v1.18.5 reg.xxx.cn/kube-apiserver:v1.18.5-arm64 docker push reg.xxx.cn/kube-apiserver:v1.18.5-arm64 创建清单 docker manifest create reg.xxx.cn/kube-apiserver:v1.18.5 \\ reg.xxx.cn/kube-apiserver:v1.18.5-arm64 \\ reg.xxx.cn/kube-apiserver:v1.18.5-amd64 指定清单镜像中对应的架构 docker manifest annotate reg.xxx.cn/kube-apiserver:v1.18.5 \\ reg.xxx.cn/kube-apiserver:v1.18.5-arm64 --arch arm64 docker manifest annotate reg.xxx.cn/kube-apiserver:v1.18.5 \\ reg.xxx.cn/kube-apiserver:v1.18.5-amd64 --arch amd64 上传镜像 docker manifest push reg.xxx.cn/kube-apiserver:v1.18.5 使用这种方式特别繁琐，查找一番发现了一个工具skopeo 可以使用该工具简化上传 skopeo同步 项目地址：https://github.com/containers/skopeo ","date":"2021-03-19","objectID":"/la-qu-shang-chuan-duo-jia-gou-jing-xiang-de-fang-fa/:0:0","tags":["docker"],"title":"拉取上传多架构镜像的方法","uri":"/la-qu-shang-chuan-duo-jia-gou-jing-xiang-de-fang-fa/"},{"categories":["docker"],"content":"安装 该存储库可能包含比较新的内容，用于生产环境前请检查一下。 centos7: sudo curl -L -o /etc/yum.repos.d/devel:kubic:libcontainers:stable.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/CentOS_7/devel:kubic:libcontainers:stable.repo sudo yum -y install skopeo ","date":"2021-03-19","objectID":"/la-qu-shang-chuan-duo-jia-gou-jing-xiang-de-fang-fa/:1:0","tags":["docker"],"title":"拉取上传多架构镜像的方法","uri":"/la-qu-shang-chuan-duo-jia-gou-jing-xiang-de-fang-fa/"},{"categories":["docker"],"content":"使用 skopeo copy --all docker://k8s.gcr.io/kube-apiserver:v1.18.15 docker://reg.xxx.cn/kube-apiserver:1.18.15 —all 同步清单中所有镜像，如果不加的话只会复制当前系统架构的镜像 这样就很简单了，而且同步速度也特别快 ","date":"2021-03-19","objectID":"/la-qu-shang-chuan-duo-jia-gou-jing-xiang-de-fang-fa/:2:0","tags":["docker"],"title":"拉取上传多架构镜像的方法","uri":"/la-qu-shang-chuan-duo-jia-gou-jing-xiang-de-fang-fa/"},{"categories":["docker"],"content":"使用docker方式编译出来的文件在华为云鲲鹏上运行缺少库，所以选择直接在鲲鹏虚机上编译 安装python3 yum install git python36 python36-devel python36-pip zlib-devel -y python3 -m pip install --upgrade pip # 更新pip 开始编译 拉取compose项目 git clone https://github.com/docker/compose.git 创建venv 环境 cd compose/ python3 -m venv venv source ./venv/bin/activate python setup.py develop 安装依赖 yum install libffi-devel 安装一些依赖库 python setup.py develop pip install -r ./requirements-build.txt 开始编译 pyinstaller -F ./docker-compose.spec 相关错误解决： ","date":"2021-03-11","objectID":"/bian-yi-docker-compose-armban-ben/:0:0","tags":["docker"],"title":"编译docker-compose arm版本","uri":"/bian-yi-docker-compose-armban-ben/"},{"categories":["docker"],"content":"ModuleNotFoundError: No module named ‘setuptools_rust’ pip install --upgrade setuptools ","date":"2021-03-11","objectID":"/bian-yi-docker-compose-armban-ben/:1:0","tags":["docker"],"title":"编译docker-compose arm版本","uri":"/bian-yi-docker-compose-armban-ben/"},{"categories":["docker"],"content":"compose/GITSHA No such file or directory 删除以下内容，注意, 也要删除 , ( 'compose/GITSHA', 'compose/GITSHA', 'DATA' ) 参考资料 https://blog.csdn.net/qq_28808029/article/details/107221921 ","date":"2021-03-11","objectID":"/bian-yi-docker-compose-armban-ben/:2:0","tags":["docker"],"title":"编译docker-compose arm版本","uri":"/bian-yi-docker-compose-armban-ben/"},{"categories":["前端"],"content":"在做namespace克隆的时候需要用到两个下拉框选择源namespace和目标namespace,用到了element的el-select组件，发现了一个有问题，使用object作为值，选择下拉框都会只显示最后一个数据。 数据如下： 代码如下： \u003cel-select v-model=\"sourceCluster\" placeholder=\"源集群\"\u003e \u003cel-option v-for=\"item in clusterOptions\" :key=\"item.id\" :label=\"item.cluster + '/' + item.namespace\" :value=\"item\"\u003e \u003c/el-option\u003e \u003c/el-select\u003e \u003c/el-form-item\u003e \u003cel-form-item label=\"克隆到\"\u003e \u003cel-select v-model=\"targetCluster\" placeholder=\"目标集群\"\u003e \u003cel-option v-for=\"item in clusterOptions\" :key=\"item.id\" :label=\"item.cluster + '/' + item.namespace\" :value=\"item\"\u003e \u003c/el-option\u003e \u003c/el-select\u003e 查看官方文档发现，如果使用对象类型时，要添加value-key 作为value的唯一标识键名，修改后如下： \u003cel-select v-model=\"sourceCluster\" value-key=\"id\" placeholder=\"源集群\"\u003e \u003cel-option v-for=\"item in clusterOptions\" :key=\"item.id\" :label=\"item.cluster + '/' + item.namespace\" :value=\"item\"\u003e \u003c/el-option\u003e \u003c/el-select\u003e \u003c/el-form-item\u003e \u003cel-form-item label=\"克隆到\"\u003e \u003cel-select v-model=\"targetCluster\" value-key=\"id\" placeholder=\"目标集群\"\u003e \u003cel-option v-for=\"item in clusterOptions\" :key=\"item.id\" :label=\"item.cluster + '/' + item.namespace\" :value=\"item\"\u003e \u003c/el-option\u003e \u003c/el-select\u003e 可以正常选择了。 ","date":"2021-02-17","objectID":"/el-selectshi-yong-objectzuo-wei-valuezhi/:0:0","tags":["element"],"title":"el-select使用object作为value值","uri":"/el-selectshi-yong-objectzuo-wei-valuezhi/"},{"categories":["kubernetes"],"content":"线下测试环境升级k8s集群过了几天后，研发同学报了一个问题，myhuaweicloud.com域名无法访问，之前是可以的。 进入到所在pod内，ping myhuaweicloud.com试了下无法解析域名，再ping baidu.com 和其他域名是正常的，猜测大概率问题出在了coredns上，先把coredns debug日至打开观察一下 .:53 { ... log debug ... } 在容器内pingmyhuaweicloud.com ，查看日志发现search域 和绝对域名都解析不到，这就很奇怪了。 然后查看了一下coredns配置，发现了问题，因为我们k8s内应用访问外网统一都是走的egress,有一些sdk支持代理就直接使用了，还有一些无法使用代理的，我们会在coredns把域名解析到egress的地址上，这样就会走egress代理了。 问题就在于上次升级后把coredns也更新了，configmap添加的custom.db文件和deployment挂载的配置都没了，随后把这个添加上恢复正常了。 后面要注意升级k8s后，这些系统组件的配置变化，避免踩坑。 ","date":"2021-02-02","objectID":"/pai-cha-k8sji-qun-sheng-ji-hou-mou-ge-wai-wang-yu-ming-wu-fa-fang-wen/:0:0","tags":["错误总结","kubernetes"],"title":"排查k8s集群升级后某个外网域名无法访问","uri":"/pai-cha-k8sji-qun-sheng-ji-hou-mou-ge-wai-wang-yu-ming-wu-fa-fang-wen/"},{"categories":["elasticsearch"],"content":"没使用docker之前，在安装/升级es时处理插件特别麻烦，每个节点都需要安装/升级对应插件，使用docker后只需要把需要用到的插件预先安装到镜像中就可以了。 ","date":"2021-01-31","objectID":"/elasticsearch-dockerjing-xiang-tian-jia-cha-jian/:0:0","tags":["docker","elasticsearch"],"title":"elasticsearch docker镜像添加插件","uri":"/elasticsearch-dockerjing-xiang-tian-jia-cha-jian/"},{"categories":["elasticsearch"],"content":"Dockerfile 在官方提供的镜像基础上利用多阶段构建添加了ik pinyin repository-s3 等插件 FROM alpine:3.9 as builder WORKDIR /opt RUN echo \"http://mirrors.aliyun.com/alpine/v3.9/main/\" \u003e /etc/apk/repositories \u0026\u0026 \\ echo \"http://mirrors.aliyun.com/alpine/v3.9/community/\" \u003e\u003e /etc/apk/repositories \u0026\u0026 \\ apk update \u0026\u0026 \\ apk upgrade \u0026\u0026 \\ apk add wget \u0026\u0026 \\ wget -O ik.zip https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.10.2/elasticsearch-analysis-ik-{{ES_VERSION}}.zip \u0026\u0026 \\ wget -O pinyin.zip https://github.com/medcl/elasticsearch-analysis-pinyin/releases/download/v7.10.2/elasticsearch-analysis-pinyin-{{ES_VERSION}}.zip \u0026\u0026 \\ wget -O repository-s3.zip https://artifacts.elastic.co/downloads/elasticsearch-plugins/repository-s3/repository-s3-v7.10.2.zip FROM docker.elastic.co/elasticsearch/elasticsearch:7.10.2 COPY --from=builder /opt/ik.zip /tmp/ COPY --from=builder /opt/pinyin.zip /tmp/ COPY --from=builder /opt/repository-s3.zip /tmp/ COPY ./bin/docker-entrypoint.sh /usr/local/bin/docker-entrypoint.sh RUN bin/elasticsearch-plugin install -b file:///tmp/ik.zip \u0026\u0026\\ bin/elasticsearch-plugin install -b file:///tmp/pinyin.zip \u0026\u0026\\ bin/elasticsearch-plugin install -b file:///tmp/repository-s3.zip \u0026\u0026\\ rm -f /tmp/ik.zip \u0026\u0026\\ rm -f /tmp/pinyin.zip \u0026\u0026 \\ rm -f /tmp/repository-s3.zip \u0026\u0026 \\ chown 1000.1000 /usr/local/bin/docker-entrypoint.sh \u0026\u0026 \\ chmod 755 /usr/local/bin/docker-entrypoint.sh bin/docker-entrypoint.sh 入口启动文件，这个文件随着版本升级会有改动，制作镜像前最好查看一下目标版本的入口文件。 在官方提供的docker-entrypoint.sh基础上添加了一些插件相关的配置变量。 #!/bin/bash set -e # Files created by Elasticsearch should always be group writable too umask 0002 run_as_other_user_if_needed() { if [[ \"$(id -u)\" == \"0\" ]]; then # If running as root, drop to specified UID and run command exec chroot --userspec=1000 / \"${@}\" else # Either we are running in Openshift with random uid and are a member of the root group # or with a custom --user exec \"${@}\" fi } # Allow user specify custom CMD, maybe bin/elasticsearch itself # for example to directly specify `-E` style parameters for elasticsearch on k8s # or simply to run /bin/bash to check the image if [[ \"$1\" != \"eswrapper\" ]]; then if [[ \"$(id -u)\" == \"0\" \u0026\u0026 $(basename \"$1\") == \"elasticsearch\" ]]; then # centos:7 chroot doesn't have the `--skip-chdir` option and # changes our CWD. # Rewrite CMD args to replace $1 with `elasticsearch` explicitly, # so that we are backwards compatible with the docs # from the previous Elasticsearch versions\u003c6 # and configuration option D: # https://www.elastic.co/guide/en/elasticsearch/reference/5.6/docker.html#_d_override_the_image_8217_s_default_ulink_url_https_docs_docker_com_engine_reference_run_cmd_default_command_or_options_cmd_ulink # Without this, user could specify `elasticsearch -E x.y=z` but # `bin/elasticsearch -E x.y=z` would not work. set -- \"elasticsearch\" \"${@:2}\" # Use chroot to switch to UID 1000 exec chroot --userspec=1000 / \"$@\" else # User probably wants to run something else, like /bin/bash, with another uid forced (Openshift?) exec \"$@\" fi fi # Allow environment variables to be set by creating a file with the # contents, and setting an environment variable with the suffix _FILE to # point to it. This can be used to provide secrets to a container, without # the values being specified explicitly when running the container. # # This is also sourced in elasticsearch-env, and is only needed here # as well because we use ELASTIC_PASSWORD below. Sourcing this script # is idempotent. source /usr/share/elasticsearch/bin/elasticsearch-env-from-file if [[ -f bin/elasticsearch-users ]]; then # Check for the ELASTIC_PASSWORD environment variable to set the # bootstrap password for Security. # # This is only required for the first node in a cluster with Security # enabled, but we have no way of knowing which node we are yet. We'll just # honor the variable if it's present. if [[ -n \"$ELASTIC_PASSWORD\" ]]; then [[ -f /usr/share/elasticsearch/config/elasticsearch.keystore ]] || (run_as_other_user_if_needed elasticsearch-keystore create) ","date":"2021-01-31","objectID":"/elasticsearch-dockerjing-xiang-tian-jia-cha-jian/:1:0","tags":["docker","elasticsearch"],"title":"elasticsearch docker镜像添加插件","uri":"/elasticsearch-dockerjing-xiang-tian-jia-cha-jian/"},{"categories":["elasticsearch"],"content":"构建镜像 docker build -t elasticsearch:7.10.2-customize . 这样后面安装或者升级都不需要操心插件之类的问题了，直接替换镜像即可。 备注：上面这些文件已经放到github上了，如果有需要也可以从这里拉取 ","date":"2021-01-31","objectID":"/elasticsearch-dockerjing-xiang-tian-jia-cha-jian/:2:0","tags":["docker","elasticsearch"],"title":"elasticsearch docker镜像添加插件","uri":"/elasticsearch-dockerjing-xiang-tian-jia-cha-jian/"},{"categories":["docker"],"content":"构建多平台镜像的几种方法 ","date":"2021-01-24","objectID":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/:0:0","tags":["buildx","docker"],"title":"使用buildx构建多平台镜像","uri":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/"},{"categories":["docker"],"content":"QEMU仿真 使用qemu 仿真出很多平台，buildx集成了该特性，可以实现在其他平台构建不需要修改dockerfile ，当它需要对不同的架构运行一个二进制文件时，它会自己从binfmt_misc 处理器中已经注册的架构去加载对应的二进制文件。当然，我们需要手动在binfmt_misc处理器里去注册我们想要的架构的。 本篇文章主要介绍使用该方法来实现多平台镜像构建。 ","date":"2021-01-24","objectID":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/:1:0","tags":["buildx","docker"],"title":"使用buildx构建多平台镜像","uri":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/"},{"categories":["docker"],"content":"使用不同节点来构建 这种方式性能较好，但是并未选择这种方式，如果想深入了解，可以参考其他资料。 官方例子： $ docker buildx create --use --name mybuild node-amd64 mybuild $ docker buildx create --append --name mybuild node-arm64 $ docker buildx build --platform linux/amd64,linux/arm64 . ","date":"2021-01-24","objectID":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/:2:0","tags":["buildx","docker"],"title":"使用buildx构建多平台镜像","uri":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/"},{"categories":["docker"],"content":"交叉编译 如果开发语言对交叉编译支持较好，可以使用dockerfiles的多阶段构建，可以构建时传入BUILDPLATFORM 和TARGETPLATFORM 参数选择运行的平台及编译的平台。 FROM --platform=$BUILDPLATFORM golang:alpine AS build ARG TARGETPLATFORM ARG BUILDPLATFORM RUN echo \"I am running on $BUILDPLATFORM, building for $TARGETPLATFORM\" \u003e /log FROM alpine COPY --from=build /log /log 使用buildx构建 ","date":"2021-01-24","objectID":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/:3:0","tags":["buildx","docker"],"title":"使用buildx构建多平台镜像","uri":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/"},{"categories":["docker"],"content":"开启docker buildx 开启docker buildx插件，要求版本不低于19.03 第一种方法临时开启： $ export DOCKER_CLI_EXPERIMENTAL=enabled 第二种方法：在config.json 中开启\"experimental\": \"enabled\" $ vim ~/.docker/config.json { ... \"experimental\": \"enabled\" } 验证 $ docker buildx version github.com/docker/buildx v0.3.1-tp-docker 6db68d029599c6710a32aa7adcba8e5a344795a7 ","date":"2021-01-24","objectID":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/:4:0","tags":["buildx","docker"],"title":"使用buildx构建多平台镜像","uri":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/"},{"categories":["docker"],"content":"开启binfmt_misc 如果使用的是docker desktop默认是已经启用binfmt_misc的了 内核版本最好大于3.x，我这里用的是5.x的内核。 这里使用[docker/binfmt](https://github.com/docker/binfmt) 开启特权模式启用binfmt_misc docker run --privileged --rm docker/binfmt:a7996909642ee92942dcd6cff44b9b95f08dad64 检查是否开启成功 $ ls -l /proc/sys/fs/binfmt_misc/ total 0 -rw-r--r--. 1 root root 0 Jan 7 17:41 jexec -rw-r--r--. 1 root root 0 Jan 7 17:43 qemu-aarch64 -rw-r--r--. 1 root root 0 Jan 7 17:43 qemu-arm -rw-r--r--. 1 root root 0 Jan 7 17:43 qemu-ppc64le -rw-r--r--. 1 root root 0 Jan 7 17:43 qemu-riscv64 -rw-r--r--. 1 root root 0 Jan 7 17:43 qemu-s390x --w-------. 1 root root 0 Jan 7 17:41 register -rw-r--r--. 1 root root 0 Jan 7 17:41 status 检查是否启用处理器 $ grep -r \"enabled\" /proc/sys/fs/binfmt_misc/ /proc/sys/fs/binfmt_misc/qemu-riscv64:enabled /proc/sys/fs/binfmt_misc/qemu-s390x:enabled /proc/sys/fs/binfmt_misc/qemu-ppc64le:enabled /proc/sys/fs/binfmt_misc/qemu-arm:enabled /proc/sys/fs/binfmt_misc/qemu-aarch64:enabled /proc/sys/fs/binfmt_misc/jexec:enabled grep: /proc/sys/fs/binfmt_misc/register: Invalid argument /proc/sys/fs/binfmt_misc/status:enabled ","date":"2021-01-24","objectID":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/:5:0","tags":["buildx","docker"],"title":"使用buildx构建多平台镜像","uri":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/"},{"categories":["docker"],"content":"创建builder 需要创建一个新的docker builder，名称叫builder $ docker buildx create --name builder --use builder $ docker buildx ls NAME/NODE DRIVER/ENDPOINT STATUS PLATFORMS builder docker-container builder0 unix:///var/run/docker.sock inactive default * docker default default running linux/amd64, linux/386 这时可以看到一个默认builder和我们新建的一个builder，目前新建的builder还处于inactive的状态。 通过如下方式启动新的builder。 $ docker buildx inspect builder --bootstrap [+] Building 63.8s (1/1) FINISHED =\u003e [internal] booting buildkit 63.8s =\u003e =\u003e pulling image moby/buildkit:buildx-stable-1 61.9s =\u003e =\u003e creating container buildx_buildkit_builder0 1.9s Name: builder Driver: docker-container Nodes: Name: builder0 Endpoint: unix:///var/run/docker.sock Status: running Platforms: linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 ","date":"2021-01-24","objectID":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/:6:0","tags":["buildx","docker"],"title":"使用buildx构建多平台镜像","uri":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/"},{"categories":["docker"],"content":"构建多平台镜像 当前目录结构： $ tree ├── Dockerfile └── test.go Dockerfile: FROM golang:1.15-alpine AS builder WORKDIR /opt RUN go build -o test . FROM alpine WORKDIR /opt COPY --from=builder /opt/test . CMD [\"./test\"] test.go package main import ( \"fmt\" ) func main() { fmt.Println(\"test\") } 开始构建并上传，注意harbor 版本要在2.0 以上才支持。 $ docker buildx build -t reg.xxxxxx.cn/app/test-golang:v1 --platform=linux/arm64,linux/amd64 --push . [+] Building 5.2s (22/22) FINISHED =\u003e [internal] load build definition from Dockerfile 0.0s =\u003e =\u003e transferring dockerfile: 92B 0.0s =\u003e [internal] load .dockerignore 0.0s =\u003e =\u003e transferring context: 2B 0.0s =\u003e [linux/amd64 internal] load metadata for docker.io/library/alpine:latest 2.3s =\u003e [linux/amd64 internal] load metadata for docker.io/library/golang:1.15-alpine 2.0s =\u003e [linux/arm64 internal] load metadata for docker.io/library/alpine:latest 3.1s =\u003e [linux/arm64 internal] load metadata for docker.io/library/golang:1.15-alpine 2.1s =\u003e [linux/amd64 builder 1/4] FROM docker.io/library/golang:1.15-alpine@sha256:49b4eac11640066bc72c74b70202478b7d431c7d8918e0973d6e4aeb8b3129d2 0.0s =\u003e =\u003e resolve docker.io/library/golang:1.15-alpine@sha256:49b4eac11640066bc72c74b70202478b7d431c7d8918e0973d6e4aeb8b3129d2 0.0s =\u003e [linux/arm64 stage-1 1/3] FROM docker.io/library/alpine@sha256:3c7497bf0c7af93428242d6176e8f7905f2201d8fc5861f45be7a346b5f23436 0.1s =\u003e =\u003e resolve docker.io/library/alpine@sha256:3c7497bf0c7af93428242d6176e8f7905f2201d8fc5861f45be7a346b5f23436 1.8s =\u003e [linux/arm64 builder 1/4] FROM docker.io/library/golang:1.15-alpine@sha256:49b4eac11640066bc72c74b70202478b7d431c7d8918e0973d6e4aeb8b3129d2 0.1s =\u003e =\u003e resolve docker.io/library/golang:1.15-alpine@sha256:49b4eac11640066bc72c74b70202478b7d431c7d8918e0973d6e4aeb8b3129d2 0.0s =\u003e [linux/amd64 stage-1 1/3] FROM docker.io/library/alpine@sha256:3c7497bf0c7af93428242d6176e8f7905f2201d8fc5861f45be7a346b5f23436 0.1s =\u003e =\u003e resolve docker.io/library/alpine@sha256:3c7497bf0c7af93428242d6176e8f7905f2201d8fc5861f45be7a346b5f23436 0.0s =\u003e [internal] load build context 0.0s =\u003e =\u003e transferring context: 178B 0.0s =\u003e CACHED [linux/amd64 stage-1 2/3] WORKDIR /opt 0.0s =\u003e CACHED [linux/amd64 builder 2/4] WORKDIR /opt 0.0s =\u003e CACHED [linux/amd64 builder 3/4] ADD . /opt/ 0.0s =\u003e CACHED [linux/amd64 builder 4/4] RUN go build -o test . 0.0s =\u003e CACHED [linux/amd64 stage-1 3/3] COPY --from=builder /opt/test . 0.0s =\u003e CACHED [linux/arm64 stage-1 2/3] WORKDIR /opt 0.0s =\u003e CACHED [linux/arm64 builder 2/4] WORKDIR /opt 0.0s =\u003e CACHED [linux/arm64 builder 3/4] ADD . /opt/ 0.0s =\u003e CACHED [linux/arm64 builder 4/4] RUN go build -o test . 0.0s =\u003e CACHED [linux/arm64 stage-1 3/3] COPY --from=builder /opt/test . 0.0s =\u003e exporting to image 1.8s =\u003e =\u003e exporting layers 0.6s =\u003e =\u003e exporting manifest sha256:714e4f18895bb698c65392eda3b39e35b38df0e84c34ce1f604bfa8fdb466a77 0.0s =\u003e =\u003e exporting config sha256:0339ab69edd09e4038046c8c056305733f050918725b6f265780189c0bdd76e3 0.0s =\u003e =\u003e exporting manifest sha256:a5c4695278c99a1801c557e68145d7a1e61fa82288a9d2b43b1f85219dea5b8a 0.0s =\u003e =\u003e exporting config sha256:a69d7dfa854e466d743d09c3c95ebca68f2feb6cb335bc0aecc4a256cc95e68f 0.0s =\u003e =\u003e exporting manifest list sha256:77677ebebf2dda103c6cd8598018a1d9bb79e06102173588fef5c501e81f6cb3 0.0s =\u003e =\u003e pushing layers 0.5s =\u003e =\u003e pushing manifest for reg.xxxxxx.cn/app/test-golang:v1 ","date":"2021-01-24","objectID":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/:7:0","tags":["buildx","docker"],"title":"使用buildx构建多平台镜像","uri":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/"},{"categories":["docker"],"content":"开机启动 由于重启后binfmt_misc 和builder 都会停止，所以要进行一些修改。 binfmt_misc 加入开机启动脚本 cat \u003e /etc/rc.d/init.d/enable-binfmt.sh \u003c\u003c EOF #!/bin/bash docker run --privileged --rm docker/binfmt:a7996909642ee92942dcd6cff44b9b95f08dad64 EOF builder 添加--restart=always BUILDER=$(docker ps | grep buildkitd | awk '{print $1}') docker update --restart=always $BUILDER 遇到的错误 ","date":"2021-01-24","objectID":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/:8:0","tags":["buildx","docker"],"title":"使用buildx构建多平台镜像","uri":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/"},{"categories":["docker"],"content":"上传镜像时x509: certificate signed by unknown authority 完整报错： failed to solve: rpc error: code = Unknown desc = failed to do request: Head [\u003chttps://reg.xxxxxx.cn/v2/app/test-golang/blobs/sha256:0c1f186a05c7a4d0cb23b4a339473c5e96115be11f4deb24f74d3f2324120c87:\u003e](\u003chttps://reg.xxxxxx.cn/v2/app/test-golang/blobs/sha256:0c1f186a05c7a4d0cb23b4a339473c5e96115be11f4deb24f74d3f2324120c87:\u003e) x509: certificate signed by unknown authority 这是因为公司所用的harbor证书是自签名证书，暂时的解决方法是将harbor证书加到builder容器中。 $ BUILDER=$(docker ps | grep buildkitd | awk '{print $1}') $ docker cp ./harbor.crt $BUILDER:/usr/local/share/ca-certificates/ # harbor.crt为harbor ca证书 $ sudo docker exec $BUILDER update-ca-certificates $ sudo docker restart $BUILDER 重新上传镜像即可。 ","date":"2021-01-24","objectID":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/:9:0","tags":["buildx","docker"],"title":"使用buildx构建多平台镜像","uri":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/"},{"categories":["docker"],"content":"docker: ‘buildx’ is not a docker command. 开启buildx后还是报这个错，查看了下和之前成功安装的环境信息 有问题的： cat /etc/redhat-release CentOS Linux release 7.3.1611 (Core) 正常的： cat /etc/redhat-release CentOS Linux release 7.5.1804 (Core) 发现是linux版本有差异，进行更新后可以正常使用 yum update -y 参考链接 https://docs.docker.com/buildx/working-with-buildx/ https://zhuanlan.zhihu.com/p/227048978 https://github.com/docker/buildx/issues/80 https://github.com/bryant-rh/buildx-example ","date":"2021-01-24","objectID":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/:10:0","tags":["buildx","docker"],"title":"使用buildx构建多平台镜像","uri":"/shi-yong-buildxgou-jian-duo-ping-tai-jing-xiang/"},{"categories":["docker"],"content":"两个服务器地址： 172.17.5.10 192.168.90.100 从172.17.5.10 telnet 192.168.90.100 提示noroute to host 172.17.5.10抓包，发出去了但是没收到回包 [root@vlnx005010 ~]# tcpdump -i eth0 -A port 80 and host 192.168.90.100 -vvv tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes 11:20:15.637884 IP (tos 0x10, ttl 64, id 37097, offset 0, flags [DF], proto TCP (6), length 60) localhost.50038 \u003e localhost.http: Flags [S], cksum 0xcc56 (incorrect -\u003e 0x5db9), seq 321553758, win 29200, options [mss 1460,sackOK,TS val 973542839 ecr 0,nop,wscale 8], length 0 E..\u003c..@.@...... ..Zd.v.P.*.^......r..V......... :........... 192.168.90.100抓包，接受到了包，但是没回包 [root@SFADMS dts]# tcpdump -A port 80 -vvv tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 10:41:31.312762 IP (tos 0x10, ttl 59, id 33216, offset 0, flags [DF], proto TCP (6), length 60) 172.17.5.10.7598 \u003e SFADMS.localdomain.http: Flags [S], cksum 0x96df (correct), seq 1563107213, win 29200, options [mss 1460,sackOK,TS val 971218509 ecr 0,nop,wscale 8], length 0 E..\u003c..@.;...... ..Zd...P]+........r............ 9..M........ 到这里估计和防火墙规则有关系，突然想起来了昨天修改过docker网段，估计是没更新，执行以下操作后，可以正常通信。 故障时没有看相关错误的信息，直接清空了，下回有时间测试一下补充上。 iptables -F systemctl restart docker ","date":"2021-01-24","objectID":"/telnet-docker-zhuan-fa-de-duan-kou-no-route-to-host/:0:0","tags":["docker","错误总结"],"title":"telnet docker 转发的端口no route to host","uri":"/telnet-docker-zhuan-fa-de-duan-kou-no-route-to-host/"},{"categories":["golang"],"content":"滑动窗口算法相比较固定窗口算法的改进是解决了固定窗口切换时可能会产生两倍于阈值流量请求的缺点。 示例： package main import ( \"log\" \"sync\" \"time\" ) type counterSlidingWindow struct { windowSize int64 //整个滑动窗口的大小，单位秒 splitNum int64 // 切分窗口的数目大小，每个窗口对应一个桶存储数据。 currentBucket int // 当前的桶 limit int // 滑动窗口内限流大小 Bucket []int // 存放每个窗口内的计数 startTime int64 // 滑动窗口开始时间 } func NewSlidingWindow(windowSize int64, limit int, splitNum int64) *counterSlidingWindow { return \u0026counterSlidingWindow{ windowSize: windowSize, limit: limit, splitNum: splitNum, currentBucket: 0, Bucket: make([]int, splitNum), startTime: time.Now().Unix(), } } func (c *counterSlidingWindow) tryAcquire() bool { currentTime := time.Now().Unix() // 计算请求时间是否大于当前滑动窗口的最大时间 // 算出当前时间和开始时间减去窗口大小的值，作用为计算超出当前滑动窗口的时间 t := currentTime - c.windowSize - c.startTime // 如果小于或等于0则代表未超出当前滑动窗口的时间。 if t \u003c 0 { t = 0 } // 用t除以滑动窗口的份数，计算出需要滑动的数量。 windowsNum := t / (c.windowSize / c.splitNum) c.slideWindow(windowsNum) count := 0 for i := 0; i \u003c int(c.splitNum); i++ { count += c.Bucket[i] } log.Printf(\"当前滑动窗口总数为: %d\", count) if count \u003e c.limit { //log.Println(\"开始限流\") return false } index := c.getCurrentBucket() log.Println(\"当前的bucket\", index) c.Bucket[index]++ return true } func (c *counterSlidingWindow) getCurrentBucket() int { currentTime := time.Now().Unix() t := int(currentTime / (c.windowSize / c.splitNum) % c.splitNum) return t } func (c *counterSlidingWindow) slideWindow(windowsNum int64) { var ( // 滑动窗口默认设置为 splitNum slideNum int64 = c.splitNum ) if windowsNum == 0 { return } // 如果windowsNum小于splitNum，则将slideNum设置为windowsNum // 如果windowsNum大于splitNum，就代表需要滑动的窗口大于一轮了，所以直接清空当前所有滑动窗口 if windowsNum \u003c c.splitNum { slideNum = windowsNum } log.Println(\"当前要滑动的窗口数\", slideNum) for i := 0; i \u003c int(slideNum); i++ { // 根据splitNum取余，获取当前的bucket c.currentBucket = (c.currentBucket +1) % int(c.splitNum) log.Printf(\"当前清空的位置: %d, 当前的大小: %d\",c.currentBucket, c.Bucket[c.currentBucket]) c.Bucket[c.currentBucket] = 0 } c.startTime = c.startTime + windowsNum * (c.windowSize / c.splitNum) } func main() { c := NewSlidingWindow(10, 5, 5) c.tryAcquire() wg := sync.WaitGroup{} wg.Add(1) go func() { defer func() { wg.Done() }() for i:=0; i\u003c= 100; i++ { for j:=0; j\u003c1; j++ { if c.tryAcquire() { } } //time.Sleep(time.Millisecond * 1429) time.Sleep(time.Second *6) } }() go func() { defer func() { wg.Done() }() for i:=0; i\u003c= 100; i++ { for j:=0; j\u003c1; j++ { if c.tryAcquire() { } } time.Sleep(time.Millisecond * 1429) //time.Sleep(time.Second *6) } }() wg.Wait() } 输出： 2021/01/11 21:51:05 当前滑动窗口总数为: 0 2021/01/11 21:51:05 当前的bucket 2 2021/01/11 21:51:05 当前滑动窗口总数为: 1 2021/01/11 21:51:05 当前滑动窗口总数为: 1 2021/01/11 21:51:05 当前的bucket 2 2021/01/11 21:51:05 当前的bucket 2 2021/01/11 21:51:06 当前滑动窗口总数为: 3 2021/01/11 21:51:06 当前的bucket 3 2021/01/11 21:51:07 当前滑动窗口总数为: 4 2021/01/11 21:51:07 当前的bucket 3 2021/01/11 21:51:09 当前滑动窗口总数为: 5 2021/01/11 21:51:09 当前的bucket 4 2021/01/11 21:51:10 当前滑动窗口总数为: 6 2021/01/11 21:51:11 当前滑动窗口总数为: 6 2021/01/11 21:51:12 当前滑动窗口总数为: 6 2021/01/11 21:51:13 当前滑动窗口总数为: 6 2021/01/11 21:51:15 当前滑动窗口总数为: 6 2021/01/11 21:51:16 当前滑动窗口总数为: 6 2021/01/11 21:51:17 当前要滑动的窗口数 1 2021/01/11 21:51:17 当前清空的位置: 1, 当前的大小: 0 2021/01/11 21:51:17 当前滑动窗口总数为: 6 2021/01/11 21:51:17 当前滑动窗口总数为: 6 2021/01/11 21:51:19 当前要滑动的窗口数 1 2021/01/11 21:51:19 当前清空的位置: 2, 当前的大小: 3 2021/01/11 21:51:19 当前滑动窗口总数为: 3 2021/01/11 21:51:19 当前的bucket 4 2021/01/11 21:51:20 当前滑动窗口总数为: 4 2021/01/11 21:51:20 当前的bucket 0 2021/01/11 21:51:22 当前要滑动的窗口数 1 2021/01/11 21:51:22 当前清空的位置: 3, 当前的大小: 2 2021/01/11 21:51:22 当前滑动窗口总数为: 3 2021/01/11 21:51:22 当前的bucket 1 2021/01/11 21:51:23 当前要滑动的窗口数 1 2021/01/11 21:51:23 当前清空的位置: 4, 当前的大小: 2 注意：这只是测试的例子，还要考虑并发操作下考虑加锁或者使用atmoic 。 参考资料 一文搞懂高频面试题之限流算法，从算法原理到实现，再到对比分析 ","date":"2021-01-23","objectID":"/jian-dan-shi-xian-hua-dong-chuang-kou-ji-shu-qi-xian-liu/:0:0","tags":["golang","算法"],"title":"简单实现滑动窗口计数器限流","uri":"/jian-dan-shi-xian-hua-dong-chuang-kou-ji-shu-qi-xian-liu/"},{"categories":["hugo"],"content":"hugo初体验 ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:0:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"安装hugo 下载链接 我这里选择的最新版本v0.80.0，选择操作系统对应的版本即可。 下载后将hugo.exe加入到环境变量中，我是习惯创建一个bin目录，将可执行文件都放到这里。 ps 下载的时候发现链接竟然打不开了，可以通过添加hosts解决 # github 199.232.96.133 avatars0.githubusercontent.com 199.232.96.133 avatars1.githubusercontent.com 199.232.96.133 avatars2.githubusercontent.com 199.232.96.133 avatars3.githubusercontent.com 199.232.96.133 avatars4.githubusercontent.com 199.232.96.133 avatars5.githubusercontent.com 199.232.96.133 avatars6.githubusercontent.com 199.232.96.133 avatars7.githubusercontent.com 199.232.96.133 avatars8.githubusercontent.com 199.232.96.133 user-images.githubusercontent.com ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:1:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"创建一个hugo项目 $ hugo.exe new site jinnzy.github.io.source ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:2:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"安装主题 这里有两种方法我采用的第一种方法，比较方便，有什么问题可以直接修改。 第一种：下载最新的压缩包或直接clone到themes目录 $ cd jinnzy.github.io.source $ git clone https://github.com/dillonzq/LoveIt.git themes/LoveIt 第二种：使用子模块来安装 $ cd jinnzy.github.io.source $ git init $ git submodule add https://github.com/dillonzq/LoveIt.git themes/LoveIt ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:3:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"修改配置 位置：./config.toml 可以参考官方文档中3.1的示例配置，由于太大这里就不贴出来了 在这个基础上我额外修改了以下几个配置，其余的就是一些网站标题描述等的就不多说了。 # 是否使用 git 信息 enableGitInfo = true [params] gitRepo = \"jinnzy.github.io.source\" [markup] # 目录设置 [markup.tableOfContents] # 从1个#开始算标题，默认是两个#开始算标题 startLevel = 1 endLevel = 6 ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:4:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"修改文章默认的模板 位置：./archetypes/default.md --- title: \"{{ replace .Name \"-\" \" \" | title }}\" date: {{ .Date }} draft: false toc: true tags: - \"\" categories: - \"\" --- 加入了目录标签和分类等。 ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:5:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"创建第一篇文章 $ hugo new posts/hugo-blog-1.md 启动进行测试，会报错 $ hugo server -D ··· Error: Error building site: failed to render pages: render of \"page\" failed: execute of template failed: template: posts/single.html:92:124: executing \"content\" at \u003cpartial \"function/content.html\"\u003e: error calling partial: \"/Users/tc/Documents/workspace_2020/blog/themes/loveIt/layouts/partials/function/content.html:15:15\": execute of template failed: template: partials/function/content.html:15:15: executing \"partials/function/content.html\" at \u003cpartial \"function/checkbox.html\" $content\u003e: error calling partial: partial that returns a value needs a non-zero argument. -D不加也可以，因为前面已经设置 draft: false 了。 这里报错是一个bug，已经有人pr但是并未合并进来，所以要自己手动修改一下。 修改文件：themes/loveIt/layouts/partials/function/content.html 修改后如下 {{- $content := .Content -}} {{- if ne \"\" $content -}} {{- if .Ruby -}} {{- $content = partial \"function/ruby.html\" $content -}} {{- end -}} {{- if .Fraction -}} {{- $content = partial \"function/fraction.html\" $content -}} {{- end -}} {{- if .Fontawesome -}} {{- $content = partial \"function/fontawesome.html\" $content -}} {{- end -}} {{- $content = partial \"function/checkbox.html\" $content -}} {{- $content = partial \"function/escape.html\" $content -}} {{- end -}} {{- return $content -}} 随后再次启动，进入[http://localhost:1313](http://localhost:1313/) 就可以看到博客首页了。 利用github pages部署blog 前置条件：需要安装git ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:6:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"创建github仓库 登录github创建库 我这里是创建了两个库 jinnzy.github.io.source 选择的是私有库(Private)存放hugo源文件，利用github actions来编译生成静态文件推送到jinnzy.github.io库中 jinnzy.github.io 选择的是公共库(Public)存放hugo编译后的静态页面，主要是通过github pages功能访问这些静态文件。 ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:7:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"配置github ssh key 生成ssk key $ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: 53:0e:0b:0f:c0:b8:d3:4f:e1:8a:a8:5d:8c:8f:98:cf jinzhy@vlnx107005.firstshare.cn The key's randomart image is: +--[ RSA 2048]----+ | o. | | . ... | | o .o.. . | | o . o+ = | | . = + S . | |. o + . . | |.+ + | |+.o . | | .E | +-----------------+ /root/.ssh/id_rsa 私钥 /root/.ssh/id_rsa.pub 公钥 打开jinnzy.github.io.source 库添加Secrets ，名称为ACTIONS_DEPLOY_KEY，将/root/.ssh/id_rsa的内容复制进去 打开jinnzy.github.io 库添加Deploy keys ，名称随便都行，将/root/.ssh/id_rsa.pub的内容复制进去。 ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:8:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"配置github actions 打开jinnzy.github.io.source，创建Actions 全部内容如下： name: Deploy Hugo Site to Github Pages on Main Branch on: push: branches: - main jobs: build-deploy: runs-on: ubuntu-18.04 steps: - uses: actions/checkout@v2 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: '0.80.0' extended: true # 使用扩展版 - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} # 这里的 ACTIONS_DEPLOY_KEY 则是上面设置 Private Key的变量名 external_repository: jinnzy/jinnzy.github.io # Pages 远程仓库 publish_dir: ./public keep_files: false # remove existing files publish_branch: main # deploying branch commit_message: ${{ github.event.head_commit.message }} ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:9:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"上传hugo项目传到github 当前所在目录：./jinzhy.github.io.source $ git init $ git commit -m \"first commit\" $ git branch -M main $ git remote add origin https://github.com/jinnzy/jinzhy.github.io.source.git $ git pull # 先把之前提交的的内容拉取下来 $ git push -u origin main 进入Actions 可以看到上传成功了 打开jinzhy.github.io 项目 下拉找到GitHub Pages 可以看到发布地址，这时访问https://jinnzy.github.io 就可以看到博客了。 Console报错找不到/site.webmanifest 引用自lewky.cn博客中的内容。 该文件和Progressive web applications (PWA)有关，通过添加PWA到Hugo站点，可以实现离线访问的功能，也就是说断网状态下依然可以访问到你之前访问过的网页，换言之就是通过PWA来将访问过的网页资源缓存到了本地，所以断网下仍然可以继续访问网站。当然，恢复网络时会自动更新最新的页面资源。 但是目前该功能还不够完善，可能存在着安全性的问题，并且实现过程也比较繁杂，最终还是决定把这个引用给去掉，做法如下： 把博客主题目录下的\\themes\\LoveIt\\layouts\\partials\\head\\link.html拷贝到根目录下的\\layouts\\partials\\head\\link.html 打开拷贝后的link.html，把\u003clink rel=\"manifest\" href=\"/site.webmanifest\"\u003e删掉或者注释掉： {{- /* \u003clink rel=\"manifest\" href=\"/site.webmanifest\"\u003e */ -}} 添加友链 注意：参考了Reference中的几篇文章添加友链，发现css样式总是不生效，查了一下午才在这个pr中发现loveit 主题某些功能需要把scss 转换为css 所以要选择扩展版下载，所以又重新下载了hugo_extended_0.80.0_Windows-64bit 这个版本😭。 主要使用kkkgo/hugo-friendlinks项目中的代码。 ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:10:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"添加友链样式 位置：jinnzh.github.io.source/assets/css/_custom.scss // friendslink .myfriends { text-align: center; background-color: #fff; opacity: 0.9; } .myfriends a { color: black; } .myfriends p { display: none; } .friendurl { text-decoration: none !important; color: black; } .myfriend { width: 56px !important; height: 56px !important; border-radius: 50%; border: 1px solid #ddd; padding: 2px; box-shadow: 1px 1px 1px rgba(0,0,0, .15); margin-top: -12px !important; margin-left: 10px !important; background-color: #fff; } .frienddiv { position: relative; left: 0; right: 0; width: 100%; height: 70px; line-height: 1.38; margin-top: -5px; margin-bottom: -5px; border-radius: 5px; background: rgba(255, 255, 255, .2); box-shadow: 4px 4px 2px 1px rgba(0, 0, 255, .2); overflow: hidden; } .frienddiv:hover { background: rgba(87, 142, 224, 0.15); } .frienddiv:hover .frienddivleft img { transition: .9s!important; -webkit-transition: .9s!important; -moz-transition: .9s!important; -o-transition: .9s!important; -ms-transition: .9s!important; transform: rotate(360deg)!important; -webkit-transform: rotate(360deg)!important; -moz-transform: rotate(360deg)!important; -o-transform: rotate(360deg)!important; -ms-transform: rotate(360deg)!important; } .frienddivleft { width: 92px; float: left; } .frienddivleft { margin-top: 15px; margin-right: 2px; } .frienddivright { margin-top: 15px; text-overflow: ellipsis; overflow: hidden; white-space: nowrap; } ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:11:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"创建shortcodes友链文件 位置：jinnzh.github.io.source/layouts/shortcodes/friend.html {{ if .IsNamedParams }} \u003cp\u003e\u003ca target=\"_blank\" href={{ .Get \"url\" }} title={{ .Get \"name\" }} class=\"friendurl\"\u003e \u003cdiv class=\"frienddiv\"\u003e \u003cdiv class=\"frienddivleft\"\u003e \u003cimg class=\"myfriend\" src={{ .Get \"logo\" }} /\u003e \u003c/div\u003e \u003cdiv class=\"frienddivright\"\u003e {{ .Get \"name\" }}\u003cbr /\u003e{{ .Get \"word\" }} \u003c/div\u003e \u003c/div\u003e \u003c/a\u003e \u003c/p\u003e {{ end }} ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:12:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"创建friend md文件 位置：jinnzh.github.io.source/content/friends.md 友链 --- hiddenFromSearch: true --- # 友链 {{\u003c friend name=\"Dillon\" url=\"https://github.com/dillonzq/\" logo=\"https://avatars0.githubusercontent.com/u/30786232?s=460\u0026u=5fc878f67c869ce6628cf65121b8d73e1733f941\u0026v=4\" word=\"LoveIt主题作者\" \u003e}} 这里的friend 是引用上个步骤中创建的friend shortcodes ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:13:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["hugo"],"content":"菜单中添加友链 位置：jinnzh.github.io.source/config.toml [menu] [[menu.main]] identifier = \"friends\" pre = \"\" post = \"\" name = \"友链\" url = \"/friends/\" title = \"\" weight = 4 weight按菜单顺序往下排即可。 最终效果 添加不蒜子，展示网站访问人数 这里的操作都在jinnzy.github.io.source 项目内操作 复制baseof.html 文件 $ mkdir -p ./layouts/_default # 没有目录则创建 $ cp themes/LoveIt/layouts/_default/baseof.html layouts/_default/baseof.html 打开刚复制的layouts/_default/baseof.html ，添加\u003cscript async src=\"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"\u003e\u003c/script\u003e ，引入不蒜子js文件 {{- partial \"init.html\" . -}} \u003c!DOCTYPE html\u003e \u003chtml lang=\"{{ .Site.LanguageCode }}\"\u003e \u003chead\u003e \u003cscript async src=\"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"\u003e\u003c/script\u003e \u003cmeta charset=\"utf-8\"\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e \u003cmeta name=\"robots\" content=\"noodp\" /\u003e \u003cmeta http-equiv=\"X-UA-Compatible\" content=\"IE=edge, chrome=1\"\u003e \u003ctitle\u003e {{- block \"title\" . }}{{ .Site.Title }}{{ end -}} \u003c/title\u003e {{- partial \"head/meta.html\" . -}} {{- partial \"head/link.html\" . -}} {{- partial \"head/seo.html\" . -}} \u003c/head\u003e ... 打开config.toml ，修改以下配置 [params.footer] enable = true # 自定义内容 (支持 HTML 格式) custom = '\u003cspan id=\"busuanzi_container_site_pv\"\u003e本站总访问量\u003cspan id=\"busuanzi_value_site_pv\"\u003e\u003c/span\u003e次\u003c/span\u003e • \u003cspan id=\"busuanzi_container_site_uv\"\u003e访客数\u003cspan id=\"busuanzi_value_site_uv\"\u003e\u003c/span\u003e人次\u003c/span\u003e' 最终效果： 由于是本地测试，域名都是localhost所以显示这么大的量是正常的，发布后使用真实域名数量就会显示正常 使用valine作为评论系统 登录或注册leancloud，点击左上角创建应用。 创建好之后，进入应用，选择设置 \u003e应用Keys，获取AppID 和App Key 。 打开项目根目录下的config.toml，填入上个步骤获取的AppID 和App Key。 [params.page.comment] enable = true [params.page.comment.valine] enable = true appId = \"xxxxx\" appKey = \"xxxxx\" 运行项目进行测试，设置变量为production 环境，默认是dev 不显示评论等系统。 $ hugo server --environment production 进入文章，看最底部已经有评论出现了。 使用自定义域名 参考资料 https://lewky.cn/tags/hugo/ https://hugoloveit.com/zh-cn/categories/ kkkgo/hugo-friendlinks友链 loveit自定义样式 不蒜子 https://valine.js.org/quickstart.html 推送百度站长 ","date":"2021-01-23","objectID":"/shi-yong-hugolai-da-jian-ge-ren-blog/:14:0","tags":["hugo"],"title":"使用hugo来搭建个人blog","uri":"/shi-yong-hugolai-da-jian-ge-ren-blog/"},{"categories":["kubernetes"],"content":"环境信息 当前版本：v1.17.5 目标版本：1.18.15 升级方式：kubeadm 推荐升级的版本为当前版本+1如1.16 升级到1.17 ，1.17 升级到1.18 查看当前yum 源里是否有模板版本，如果没有的话需要更新yum 源。 yum list --showduplicates kubeadm --disableexcludes=kubernetes ··· kubeadm.x86_64 1.18.13-0 kubernetes kubeadm.x86_64 1.18.14-0 kubernetes kubeadm.x86_64 1.18.15-0 kubernetes kubeadm.x86_64 1.19.0-0 kubernetes kubeadm.x86_64 1.19.1-0 kubernetes kubeadm.x86_64 1.19.2-0 kubernetes ··· 升级master节点 ","date":"2021-01-23","objectID":"/k8s-1-17-sheng-ji-dao-1-18/:0:0","tags":["kubernetes","kubernetes升级"],"title":"k8s 1.17 升级到 1.18","uri":"/k8s-1-17-sheng-ji-dao-1-18/"},{"categories":["kubernetes"],"content":"准备升级所需镜像 查看所需镜像，将这些镜像拉取下来传到私有仓库里，可使用kubeadm config images list 查看所需镜像版本(会列出当前kubeadm版本所需镜像，如果不确定需要拉取哪些镜像，可以升级到对应版本的kubeadm运行查看所需镜像)。 k8s.gcr.io/kube-apiserver:v1.18.15 k8s.gcr.io/kube-controller-manager:v1.18.15 k8s.gcr.io/kube-scheduler:v1.18.15 k8s.gcr.io/kube-proxy:v1.18.15 k8s.gcr.io/pause:3.2 k8s.gcr.io/etcd:3.4.3-0 k8s.gcr.io/coredns:1.6.7 我目前是从registry.cn-hangzhou.aliyuncs.com/google_containers 这个仓库拉取镜像。 pullReg=registry.cn-hangzhou.aliyuncs.com/google_containers pushReg=reg.xxx.cn/k8s.gcr.io for i in $(echo -n 'k8s.gcr.io/kube-apiserver:v1.18.15 k8s.gcr.io/kube-controller-manager:v1.18.15 k8s.gcr.io/kube-scheduler:v1.18.15 k8s.gcr.io/kube-proxy:v1.18.15 k8s.gcr.io/pause:3.2 k8s.gcr.io/coredns:1.6.7');do app=$(echo $i|awk -F 'k8s.gcr.io/' '{print $2}') \u0026\u0026 \\ docker pull ${pullReg}/${app} \u0026\u0026 \\ docker tag ${pullReg}/${app} ${pushReg}/${app} \u0026\u0026 \\ docker push ${pushReg}/${app}; done ","date":"2021-01-23","objectID":"/k8s-1-17-sheng-ji-dao-1-18/:1:0","tags":["kubernetes","kubernetes升级"],"title":"k8s 1.17 升级到 1.18","uri":"/k8s-1-17-sheng-ji-dao-1-18/"},{"categories":["kubernetes"],"content":"开始升级master节点 首先升级kubeadm yum -y install kubeadm-1.18.15-0 kubectl-1.18.15 查看升级计划 [root@vlnx107024 ~]# kubeadm upgrade plan ··· External components that should be upgraded manually before you upgrade the control plane with 'kubeadm upgrade apply': COMPONENT CURRENT AVAILABLE Etcd 3.4.9 3.4.3-0 Components that must be upgraded manually after you have upgraded the control plane with 'kubeadm upgrade apply': COMPONENT CURRENT AVAILABLE Kubelet 5 x v1.17.7 v1.18.15 Upgrade to the latest version in the v1.17 series: COMPONENT CURRENT AVAILABLE API Server v1.17.7 v1.18.15 Controller Manager v1.17.7 v1.18.15 Scheduler v1.17.7 v1.18.15 Kube Proxy v1.17.7 v1.18.15 CoreDNS 1.6.5 1.6.7 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.18.15 因为这个k8s集群是使用集群外的etcd 方式，所以版本比较新，如果版本低于AVAILABLE 的版本，需要先升级etcd 开始升级第一个节点： kubeadm upgrade apply -y 1.18.15 --config=/root/kubeadm-config.yml --ignore-preflight-errors=all --force kubeadm upgrade apply 参数： --allow-experimental-upgrades : 显示不稳定版本，允许升级到alpha/beta或rc版本。 --certificate-renewal : 默认为true，执行升级期间更新证书 --config : kubeadm配置文件路径，如果没有更新配置文件可以不添加 --force : 强制升级，非交互模式 --ignore-preflight-errors : 为all 时忽略检查中的所有错误 --print-config : 是否打印升级中使用的配置文件 -y, --yes : 非交互模式。 查看更新节点的apiserver controler manager kube-schdule 状态及版本是否正常 kubectl -n kube-system get po 更新成功后重启kubelet systemctl restart kubelet 查看集群内当前节点的版本，为1,18,15 就是正常了 kubectl get nodes 随后依次更新另外两个master节点 kubeadm upgrade apply -y 1.18.15 --ignore-preflight-errors=all --force 升级node节点 node节点升级操作就更简单了 首先同样是安装包 yum -y install kubeadm-1.18.15-0 kubectl-1.18.15 最好是清空当前节点，不过由于我是升级测试环境就省略这一步，升级完节点由于结构体有变化，hash值变更会重启当前节点所有的pod进行更新。 kubectl drain --delete-local-data --force --ignore-daemonsets --grace-period=0 ${currentNodeName} 开始更新 kubeadm upgrade node 重启kubelet systemctl restart kubelet 检查节点状态 kubectl get nodes 没问题后重复此步骤，依次升级剩余节点即可。 参考资料 https://v1-18.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/ https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm-upgrade/ ","date":"2021-01-23","objectID":"/k8s-1-17-sheng-ji-dao-1-18/:2:0","tags":["kubernetes","kubernetes升级"],"title":"k8s 1.17 升级到 1.18","uri":"/k8s-1-17-sheng-ji-dao-1-18/"}]